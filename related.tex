\section{Related Work}
Research in computer animation has demonstrated robust locomotion control for challenging tasks in physically simulated environments. However, we have not seen any robots that can demonstrate similar capabilities. This gap is known as \emph{Reality Gap}: A controller that can work effectively in physical simulation may not work in the real environment. This gap is caused by sensor noise, latency, hardware limitations, unmodeled dynamics, inaccurate physical model and other unknown factors. Nolfi and Floreano \cite{Nolfi:2000} outlined the problems that are related to crossing the reality gap and identified the key difficulties. A large amount of approaches were proposed in robotics to cross this reality gap. We refer the readers to Eaton \cite{Eaton:2015} for a comprehensive review of this topic.

One way to cross the reality gap is to increase the robustness of the controller so that it is more likely to work in a different environment. A more robust controller can be found by injecting noise to the simulation \cite{Miglino94,Jakobi95,Miglino96}, leveraging multiple simulators \cite{Boeing:2012}, and optimizing the controller through ensembles of perturbed models \cite{Mordatch:2015}. Although these methods do not explicitely involve experiments on the robot during controller optimization, they have been shown effective to increase the probability of a successful controller transfer.

Another direction to close the reality gap is to improve the simulation model so that it better reflects the real world dynamics. The simulation is improved by measuring and minimizing the discrepancy between the simulation results and the data collected in robot experiments. Ha and Yamane \cite{HA:2015} modeled this discrepancy using Gaussian process. Abbeel et al. \cite{Abbeel:2006} used an inaccurate physical model but successively grounded the policy evaluations using real-life trials. Mouret et al. \cite{MouretKD13, Koos:2010} derived a measure of transferability by comparing fitness scores between the simulation and the real experiments. Grounded simulated learning approach \cite{Farchy:2013} iteratively optimized the controller, measured the discrepancy and modified the simulator using supervised learning algorithms. Bongard and Lipson \cite{BongardL05} coevolved the controller and the simulator using an iterative estimation-exploration process. Similarly, Zagal et al. \cite{zagal2004} introduced the ``back-to-reality'' approach, which also involved the coevolution but used a different measure of discrepancy. In Chapter 6, we investigate several factors that contribute to the reality gap and we present a simulation calibration process to transfer locomotion controllers from virtual to real environments.