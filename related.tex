\section{Related Work}

The transition motions that this paper foucses on involve changing postures and maintaining balance during the motion. Some of the transition tasks are extensively studied in robotics, including sit-to-stand \cite{Faloutsos:2003,Iida:2004,Pchelkin:2010,Mistry:2010} and lie-to-stand \cite{morimoto:1998,Faloutsos:2001,Hirukawa:2005,Kanehiro:2007}. While many of these prior work focuses on one specific motion, we target at a wider range of such transition tasks. A few related work tried to tackle this more general problem. Jones \cite{jones:2011} developed rising motions for both biped and quadraped using pose tracking, orientation correction and virtual force. Lin and Huang \cite{lin:2012} used motion planning and dynamics filtering to develop rising up motions from various initial lying poses. Tassa et al. \cite{tassa:2012} used Model Predictive Control to synthesize complex behaviors, including getting up from an aribitrary pose on the ground. Although these work has shown impressive results in simulation, experiments on real robots were not presented.

A controller that is designed in simulation may not work in the real environment. This discrepancy of performance is called the Reality Gap. One way to cross the reality gap is to improve the simulation model using real data that is measured from robot experiments. Ha and Yamane \cite{HA:2015} performed Gaussian process regression to model the error between the simulated and the real data, and then augmented the simulation with this error model. Abbeel et al. \cite{Abbeel:2006} started from an inaccurate physical model but successively grounded the policy evaluations using real-life trials. Grounded simulated learning approach \cite{Farchy:2013} iteratively optimized the controller, measured the discrepancy and modified the simulator using supervised learning algorithms. Zagal et al. \cite{zagal2004} coevolved the controller and the simulator using genetic algorithms. Mordatch et al. \cite{Mordatch:2015} performed trajectory optimization using ensembles of perturbed physical models, which increased the success rate when the controller was executed on the robot.

Our simulation calibration subsystem narrows down the Reality Gap using off-white dynamic system identification methods \cite{ljung:2010}. A typical dynamic system identification involve experiment design and parameter estimation \cite{swevers:2007}. Experiments could be designed manually or automatically with genetic algorithms \cite{BongardL05}. When performing system identification for transition, locomotion or manipulation tasks, in which contact changes are frequent, the experiments are usually designed independently from tasks because the parameters are better inferred with a contact free behavior \cite{Kolev:2015}. As a result, lengthy experiments and huge amount of data are needed in system identification, in the hope that the collected data covers the important regions of the control space. In contrast, our system tightly couples simulation calibration and trajectory optimization. The current reference trajectory that is optimized in the simulation is used as the experiment for system identification. Using Covariance Matrix Adaptation (CMA) \cite{Hansen:2009}, we are able to estimate parameters even with contact changes in the experiments. CMA is a stochastic sampling-based optimization algorithm, which has been successfully applied in physically-based character animation to search for control parameters when the problem domain is highly discontinous \cite{Wu:2010, Wang:2010, Tan:2014}.



