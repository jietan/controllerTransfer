\section{Introduction}

In character animation, we are able to reproduce many of the diverse and agile locomotion in nature. However, we have not yet seen the same level of motor capabilities in robotics. There is a large gap between what a character can do in the virtual environment and what a robot can do in the real world. This gap is due to the tremendous challenges when designing controllers with the real hardware since the majority of the robot controllers today are designed directly on the hardware. Robot hardware is expensive, has severe limitations (accuracy, repeatability, noise, torque limits, etc.), and requires frequent mantainance. For these reasons, designing robotic controllers is a time-consuming, labor intensive and trial-and-error process that is limited only to highly-specialized engineers. We have demonstrated in the previous Chapters that with the powerful computational tools, controllers can be designed autonomously in a virtual environment. Can we extend the computational tools developed for character animations to robotics to close the gap between these two fields?

The major challenge to directly apply the methods in character animation to robotics is the Reality Gap: Controllers that work effectively for a virtual character in the simulation may perform poorly on a robot in the real environment. The cause of the Reality Gap is the various simplifications in simulation algorithms, such as simplifying dynamics models, using inaccurate physical parameters, ignoring hardware limitations, noise and latency. For example, we do not model the internal mechanism of a servo in character animation. We often use rough estimations of the physical parameters, such as mass, COM and moment of inertia, of a character in the simulation. Even though we can acquire these parameters from the Computer-Aided Design (CAD) specification files of a robot, they are also inaccurate given the manufacturing and assembling errors. Furthermore, we usually do not model the noise in the environment and the latency in the hardware communication in character animation.

We need to cross the Reality Gap in order to tap the power of the computational tools to design robotic controllers autonomously. In this work, we develop a system with three components. In addition to physical simulation and controller optimization that we use extensively in character animation, we introduce simulation calibration to narrow down the Reality Gap. During simulation calibration, we collect the real performance data on the robot, and use it to improve our physical simulator. We optimize a set of simulation parameters to minimize the discrepancy between the simulation results and the collected real data. Through calibration, the simulator can capture the real world dynamics more faithfully. This calibrated simulator is used again in controller optimization to improve the quality of the controller. Depending on the task, a controller optimized in the simulation could be successfully transferred to a robot within a small number of iterations of simulation calibration and controller optimization. As a result, our system drastically reduces the number of time-consuming robot experiments and replaces the tedious manual tuning with an automatic optimization process. 

We evaluate our system using three locomotion tasks, rising from a leaning, sitting, or kneeling position to an erect stance. These tasks play an important role in our daily life. They are so common that we perform them many times everyday. Although most of us can achieve these tasks without difficulties, they present big challenges for some elderly persons and patients with hamspring injuries. We choose to study these motions and synthesize them on a robot given its important health-care applications. One simple solution to achieve these tasks is to utilize static balance. The robot can increase the area of the support polygon by establishing new contact points, and then rises its body slowly while maintaining the COM within the support polygon. We choose not to use this strategy because in real life, we human can perform these motions in a more agile fashion, and we hope that our controller can demonstrate comparable agility. For this reason, our controllers will utilize impulsive actions and take advantage of the accumulated momentum to rise. In addition, since the main contribution of our method is simulation calibration, to best test its effectiveness, we only use feedforward controllers in our evaluations. Otherwise, if feedback controllers are used, the stability region of the tasks could be drastically increased, which makes the simulation accuracy less critical. Our results show that simulation calibration is an effective method to cross the Reality Gap. In all the test cases, at most one iteration of calibration is needed to transfer the controller from the simulated character to the real robot. 